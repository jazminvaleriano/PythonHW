{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Week 5 - Assignment</center></h2>\n",
    "<h3><center>Programming for Data Science 2024</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the topics covered in the fifth lecture.\n",
    "\n",
    "The exercise will be marked as passed if you get **at least 10/15** points.\n",
    "\n",
    "Exercises must be handed in via **ILIAS** (Homework assignments). Deliver your submission as a compressed file (zip) containing one .py or .ipynb file with all exercises. The name of both the .zip and the .py/.ipynb file **must** be *SurnameName* of the two members of the group. Example: Riccardo Cusinato + Athina Tzovara = *CusinatoRiccardo_TzovaraAthina.zip* .\n",
    "\n",
    "It's important to use comments to explain your code and show that you're able to take ownership of the exercises and discuss them.\n",
    "\n",
    "You are not expected to collaborate outside of the group on exercises and submitting other groupsâ€™ code as your own will result in 0 points.\n",
    "\n",
    "For questions contact: *riccardo.cusinato@unibe.ch* with the subject: *Programming for Data Science 2024*.\n",
    "\n",
    "**Deadline: 14:00, March 28, 2024.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 1 - Fitbit dataset<span style=\"float: right\">3 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with three datasets - 'activity.csv', 'calories.csv', and 'last_participant.csv', which contains activity tracker data from https://www.kaggle.com/datasets/arashnic/fitbit\n",
    "\n",
    "If you are unable to do this exercise, you can load the dataset 'combined_solution.csv' for the next exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data preparation** (*1 point*)\n",
    "\n",
    "    - Load the two datasets 'activity.csv' and 'calories.csv'.\n",
    "    - Use pd.to_datetime to standardize the ActivityDate columns (https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID ActivityDate  Calories\n",
      "0    1624580081   2016-04-12    1432.0\n",
      "1    1624580081   2016-04-13    1411.0\n",
      "2    1624580081   2016-04-14    1572.0\n",
      "3    1624580081   2016-04-15    1344.0\n",
      "4    1624580081   2016-04-16       NaN\n",
      "..          ...          ...       ...\n",
      "904  8792009665   2016-05-06    1688.0\n",
      "905  8792009665   2016-05-07    1688.0\n",
      "906  8792009665   2016-05-08    1688.0\n",
      "907  8792009665   2016-05-09    1688.0\n",
      "908  8792009665   2016-05-10       NaN\n",
      "\n",
      "[909 rows x 3 columns]\n",
      "             ID ActivityDate  TotalSteps  TotalDistance  VeryActiveDistance  \\\n",
      "0    1503960366   2016-04-12     13162.0           8.50                1.88   \n",
      "1    1503960366   2016-04-13     10735.0           6.97                1.57   \n",
      "2    1503960366   2016-04-14     10460.0           6.74                2.44   \n",
      "3    1503960366   2016-04-15      9762.0           6.28                2.14   \n",
      "4    1503960366   2016-04-16     12669.0           8.16                2.71   \n",
      "..          ...          ...         ...            ...                 ...   \n",
      "904  8792009665   2016-05-06         NaN           0.00                0.00   \n",
      "905  8792009665   2016-05-07         NaN           0.00                0.00   \n",
      "906  8792009665   2016-05-08         NaN           0.00                0.00   \n",
      "907  8792009665   2016-05-09         NaN           0.00                0.00   \n",
      "908  8792009665   2016-05-10         NaN           0.00                0.00   \n",
      "\n",
      "     ModeratelyActiveDistance  LightActiveDistance  VeryActiveMinutes  \\\n",
      "0                        0.55                 6.06                 25   \n",
      "1                        0.69                 4.71                 21   \n",
      "2                        0.40                 3.91                 30   \n",
      "3                        1.26                 2.83                 29   \n",
      "4                        0.41                 5.04                 36   \n",
      "..                        ...                  ...                ...   \n",
      "904                      0.00                 0.00                  0   \n",
      "905                      0.00                 0.00                  0   \n",
      "906                      0.00                 0.00                  0   \n",
      "907                      0.00                 0.00                  0   \n",
      "908                      0.00                 0.00                  0   \n",
      "\n",
      "     FairlyActiveMinutes  LightlyActiveMinutes  \n",
      "0                     13                   328  \n",
      "1                     19                   217  \n",
      "2                     11                   181  \n",
      "3                     34                   209  \n",
      "4                     10                   221  \n",
      "..                   ...                   ...  \n",
      "904                    0                     0  \n",
      "905                    0                     0  \n",
      "906                    0                     0  \n",
      "907                    0                     0  \n",
      "908                    0                     0  \n",
      "\n",
      "[909 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the datasets\n",
    "calories_df = pd.read_csv('./data/calories.csv')\n",
    "activity_df = pd.read_csv('./data/activity.csv')\n",
    "\n",
    "# Using pd.to_datetime() to standardize the date format in ActivityDate column\n",
    "activity_df['ActivityDate']=pd.to_datetime(activity_df['ActivityDate'])\n",
    "calories_df['ActivityDate']=pd.to_datetime(calories_df['ActivityDate'])\n",
    "\n",
    "\n",
    "# Print both dataframes\n",
    "print(calories_df)\n",
    "print(activity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Merging** (*1 point*)\n",
    "\n",
    "    - Consider what information is shared between the two datasets and merge them. Keep in mind that the order of rows is not the same in both datasets!\n",
    "    - Print out the mean \"TotalSteps\" of the merged DataFrame at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of TotalSteps the merged df:  7786.439\n"
     ]
    }
   ],
   "source": [
    "# Merge the activity and calories df by ID and Activity Date\n",
    "merged_df = activity_df.merge(calories_df, on=['ID', 'ActivityDate'])\n",
    "\n",
    "\n",
    "# Calculate the mean of the merged df column \"TotalSteps\" \n",
    "mean_steps_merged = merged_df['TotalSteps'].mean()\n",
    "print('Mean of TotalSteps the merged df: ', round(mean_steps_merged,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Concatenation** (*1 point*)\n",
    "\n",
    "    - The data of one additional participant exists in 'last_participant.csv'. Load this dataset and concatenate it with the merged dataset generated above\n",
    "    - Print out the mean \"TotalSteps\" again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of TotalSteps, including last participant:  7879.461\n"
     ]
    }
   ],
   "source": [
    "# Load the data for the last additional participant, and correct the Activity Date format:\n",
    "last_df = pd.read_csv('./data/last_participant.csv')\n",
    "last_df['ActivityDate'] = pd.to_datetime(last_df['ActivityDate'])\n",
    "\n",
    "# Concatenate the merged dataframe and the last participant data:\n",
    "concatenated_df = pd.concat([merged_df, last_df], ignore_index=True)\n",
    "mean_steps=concatenated_df['TotalSteps'].mean()\n",
    "\n",
    "print(\"Mean of TotalSteps, including last participant: \",round(mean_steps,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 2 - Working with missing data<span style=\"float: right\">5 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, some values are missing from the 'TotalSteps' and 'Calories' columns.\n",
    "\n",
    "We can try to approximate these missing values with the data we got. \n",
    "\n",
    "You can load the dataset 'combined_solution.csv' if you were unable to complete the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filling in missing values** (*3 points*)\n",
    "\n",
    "    - Calculate the mean steps per calory burnt and mean calories burnt per step, by averaging across all observations in the dataset and then computing the ratio. Print out both values.\n",
    "    - Fill in the null values in the columns 'Calories' and 'TotalSteps' where possible. To fill the values you have to use the factors *\"TotalSteps/Calories\"* and *\"Calories/TotalSteps\"* calculated in the previous point, using one of the two information to fill the other.\n",
    "    - Print out the mean of the columns 'TotalSteps' and 'Calories' before and after filling the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalSteps/Calories:  3.41\n",
      "Calories/TotalSteps:  0.293\n",
      "Means before filling the values: \n",
      " TotalSteps:  7879.461 , Calories:  2310.662\n",
      "Means after filling the values: \n",
      " TotalSteps:  7426.19 , Calories:  2238.18\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean calories (mean steps were calculated in the previous exercise):\n",
    "mean_calories=concatenated_df['Calories'].mean()\n",
    "\n",
    "# Calculate the ratios \"Steps per calory burnt\" and \"Calories burnt per step\":\n",
    "steps_per_calory=mean_steps/mean_calories\n",
    "calores_per_step=mean_calories/mean_steps\n",
    "\n",
    "print(\"TotalSteps/Calories: \",round(steps_per_calory,3))\n",
    "print(\"Calories/TotalSteps: \",round(calores_per_step,3))\n",
    "\n",
    "# Filling in missing values in 'Calories' and 'TotalSteps':\n",
    "filled_concatenated_df=concatenated_df.copy() #Copy to avoid modifying the original df\n",
    "filled_concatenated_df['Calories'].fillna(filled_concatenated_df['TotalSteps'] / mean_steps, inplace=True)\n",
    "filled_concatenated_df['TotalSteps'].fillna(filled_concatenated_df['Calories'] / mean_calories, inplace=True)\n",
    "\n",
    "# Calculate new means:\n",
    "mean_steps_after_fill=filled_concatenated_df['TotalSteps'].mean()\n",
    "mean_calories_after_fill=filled_concatenated_df['Calories'].mean()\n",
    "\n",
    "# Printing the before and after means:\n",
    "print(\"Means before filling the values: \\n TotalSteps: \",round(mean_steps,3),\", Calories: \",round(mean_calories,3))\n",
    "print(\"Means after filling the values: \\n TotalSteps: \",round(mean_steps_after_fill,3),\", Calories: \",round(mean_calories_after_fill,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Dropping missing values** (*2 points*)\n",
    "\n",
    "    - Print how many null values there are in the 'Calories' and 'TotalSteps' columns, respectively.\n",
    "    - Drop the rows where **both** 'Calories' and 'TotalSteps' are missing.\n",
    "    - Print number of rows in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in 'Calories':  30\n",
      "Null values in 'TotalSteps':  55\n",
      "Number of rows in the final dataset: 956\n"
     ]
    }
   ],
   "source": [
    "# Finding and counting null values in Calories and TotalSteps:\n",
    "null_calories_count=concatenated_df['Calories'].isnull().sum()\n",
    "null_totalsteps_count=concatenated_df['TotalSteps'].isnull().sum()\n",
    "\n",
    "print(\"Null values in 'Calories': \", null_calories_count)\n",
    "print(\"Null values in 'TotalSteps': \", null_totalsteps_count)\n",
    "\n",
    "# Drop rows where both 'Calories' and 'TotalSteps' are missing\n",
    "concatenated_df.dropna(subset=['Calories', 'TotalSteps'], how='all', inplace=True)\n",
    "\n",
    "# Print the number of rows in the final dataset:\n",
    "print(\"Number of rows in the final dataset:\", concatenated_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 3 - Multi-index<span style=\"float: right\">7 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will create and manipulate a multi-index dataframe. First, let's create the dataframe for the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>A_X</th>\n",
       "      <th>A_Y</th>\n",
       "      <th>B_X</th>\n",
       "      <th>B_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  A_X  A_Y   B_X   B_Y\n",
       "0    0  1.1  1.2  1.11  1.22\n",
       "1    1  1.1  1.2  1.11  1.22\n",
       "2    2  1.1  1.2  1.11  1.22"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"idx\": [0, 1, 2],\n",
    "        \"A_X\": [1.1, 1.1, 1.1],\n",
    "        \"A_Y\": [1.2, 1.2, 1.2],\n",
    "        \"B_X\": [1.11, 1.11, 1.11],\n",
    "        \"B_Y\": [1.22, 1.22, 1.22],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set the column *idx* as the index of the dataframe. (*1 point*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'idx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df,index\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'idx'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df,index=df[\"idx\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a multi-column stucture. (*3 points*)\n",
    "    - Set the columns *A, B* on the first level and *X, Y* on the second level, taken from the combinations in the original dataframe. \n",
    "    - Set the names of the two new levels as \"L1\" and \"L2\", respectively. \n",
    "    - Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. From the previous dataframe, re-create a dataframe with a single column level. (*3 points*)\n",
    "    - Create a new column from the first level (L1) of the multi-column. At this point your columns should be ['L1', 'X', 'Y'], with name 'L2'. **NB** The DataFrame method *reset_index* is useful for this part.\n",
    "    - Rename the newly-created column as \"letter\" and the name of the column level as \"L\". Use the appropiate pandas methods for this.\n",
    "    - Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
